---
title: "HW2"
author: "Minh Luc, Devin Pham, Kyle Moore"
date: "Friday of Week 2, 04/08/2022"
output: 
  pdf_document: 
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

***
### We all contributed equally for this homework.

# Question 0 

### Member 1: 
* Name: Minh Luc
* Student ID: A17209607

### Member 2: 

* Name: Kyle Moore
* Student ID: A14271413

### Member 3: 

* Name: Devin Pham
* Student ID: A17198936

***

# Question 1

* **(a)**

    ```{r warning=FALSE}
    # install the packages if needed by using
    # install.packages("...")
    library(tidyr)
    library(readr)
    library(tidytuesdayR)
    urlRemote <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/'
    pathGithub <- 'data/2020/2020-07-28/'
    fileName <- 'penguins.csv'
    penguins <- paste0(urlRemote, pathGithub, fileName) %>% read.csv(header = TRUE)
    dfr <- drop_na(as.data.frame(penguins))
    head(dfr)
    ```

* **(b)**

    ```{r warning=FALSE}
    nrow(dfr) # number of rows
    ncol(dfr) # number of columns
    ```
  
  There are `r nrow(dfr)` rows and `r ncol(dfr)` columns in the dataframe(dfr).

***

# Question 2

* **Find the mean vector, covariance matrix and correlation matrix of X:**

    ```{r}
    X <- dfr[,3:6] # assign all rows, but only columns 3-6 to X

    colMeans(X) # mean vector containing the means for each column in X
    
    cov(X) # compute the covariance matrix of X
    
    cor(X) # compute the correlation matrix of X
    ```

* The variance-covariance matrix is a symmetric matrix that represents how the variables are correlated: positively correlated, negatively correlated, or uncorrelated. The diagonal         represents the variance of each variable itself. It is symmetric due to the fact that $\mathrm{Cov}(X,Y) = \mathrm{Cov}(Y,X)$.

* The correlation matrix is a standardized version of the variance-covariance matrix that represents the strength of the correlation between two variables where $-1 \leq correlation        \leq 1$. Entries closer to 1 are more strongly positively correlated, those closer to -1 are strongly negatively correlated, and those near 0 are weakly or uncorrelated. The diagonals     are all 1's because each variable is completely correlated with itself.

***

# Question 3

* **(a)**:

    ```{r}
    A <- cor(X) # assign the previous correlation matrix to A
    
    2 * A # scalar multiplication of A by 2
    ```

* **(b)**:

    ```{r}
    set.seed(3) # replace 1 by your own choice
    B <- matrix(rnorm(16),nrow=4) # generates a random normal matrix and assigns it to B
    
    C <- t(B) * B # assign B' * B to C
    
    print(C)
    ```
    
  * C is symmetric.

* **(c)**:

    ```{r}
    a <- 2
    b <- 3
    
    (a * A) + (b * B)
    ```

* **(d)**:

    ```{r message=FALSE, warning=FALSE}
    eigen(A)
    eigen(A)$values # eigen values
    eigen(A)$vectors  # eigen vectors
    
    library(expm)
    
    sqrtm(A)  # square root the matrix A
    ```
    
***

# Question 4

* **Create a new dataset $Y$, where $Y_1 = 3X_1 + 2X_2, Y_2 = X_2 + X_3 + X_4$**

    ```{r}
    Y <- data.frame(matrix(ncol = 2, nrow = 333)) # create new empty dataframe
    colnames(Y) <- c('Y_1', 'Y_2')  # label columns
    
    Y['Y_1'] <- as.matrix((3* X[, 1]) + (2 * X[, 2])) # linear combination of X into new column
    Y['Y_2'] <- as.matrix(X[, 2] + X[, 3] + X[, 4]) # linear combination of X into new column
    
    head(Y) # show first rows of Y
    
    colMeans(Y) # mean vector containing the means for each column in Y
    
    cov(Y) # compute the covariance matrix of Y
    ```

***

# Question 5

* **(a)**:

* **(b)**:

* **(c)**:

* **(d)**:

***